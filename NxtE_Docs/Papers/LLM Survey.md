# 1. 引言
语言建模可以分为四个主要发展阶段：
- 统计语言模型（SLM）
- 神经语言模型（NLM）
- 预训练语言模型（PLM）
- 大语言模型（LLM）

LLM 与 PLM 的三个主要区别：
1. 涌现能力
2. LLM 主要通过提示接口访问
3. LLM 的发展不在明确区分研究和工程

LLM 的基本原理相关问题：
1. 为什么涌现能力会出现在 LLM 中，而不是较小的 PLM 中
2. 研究界很难训练出有能力的 LLM
3. 将 LLM 与人类价值观或偏好保持一致是具有挑战性的

# 2. 概述
## 2.1 大语言模型的背景
### 扩展法则
- KM 扩展法则
- Chinchilla 扩展法则
KM扩展法则更偏向于将更大的预算分配给模型大小，而 Chinchilla 扩展法则则认为模型大小和数据大小应该以相同的比例增加。
### 涌现能力
- 上下文学习：ICL (In-Context Learning) 能力由 GPT-3 正式引入：假设已经为语言模型提供了一个自然语言指令和/或几个任务演示，它可以通过输入文本的单词序列的方式来测试实例生成预期的输出，而无需额外的训练或梯度更新。通过输入-输出示例，就能学会做全新的事情。
- 指令遵循：通过使用自然语言描述的混合多任务数据集进行微调，LLM在未见过的以指令形式描述的任务上表现出色。通过指令微调，LLM能够在没有使用显式示例的情况下遵循新的任务指令，因此它具有更好的泛化能力。
- 逐步推理：通过使用思维链（Chain-of-Thought, CoT）提示策略，LLM 可以通过利用包含中间推理步骤的提示机制来解决涉及多个推理步骤的复杂任务，例如数学问题。这种能力可能是通过在代码上进行训练而获得。CoT 提示的性能改进在不同的任务上也存在差异，对于 PaLM 来说，GSM8K > MAWPS > SWAMP。
### 关键技术
- 扩展：
  Transformer 语言模型存在明显的扩散效应：更大的模型/数据规模和更多的训练计算通常会导致模型能力的提升。
  由于计算资源有限，可以利用扩散法则来更高效地分配计算资源。
  数据扩展应该经过谨慎的清理过程，预训练数据的质量在模型能力中起着关键作用。
- 训练：
  分布式训练算法（通常联合使用并行策略）
  优化框架：DeepSpeed 和 Megatron-LM
  优化技巧：重新开始以和服训练损失激增、混合精度训练
- 能力引导：
  LLM在预训练后具备了作为通用任务求解器的潜在能力。设计合适的任务指令或具体的 ICL 策略可以激发这些能力。例如，CoT 提示对解决复杂的推理任务有效。
- 对齐微调：
  确保有用性、诚实性和无害性，InstructGPT 设计了一种基于人类反馈的强化学习技术的微调方法。
- 工具操作：
  利用外部工具弥补 LLM 的不足，例如不适合以文本形式表达的任务上表现不佳、无法获取最新信息。
## 2.2 GPT 系列模型的技术演进（未精读）
### 早期探索
- GPT-1
- GPT-2
### 能力飞跃
- GPT-3
### 能力增强
- 使用代码数据进行训练
  OpenAI 在 2021 年 7 月推出 Codex，是一个在大量 GitHub 代码上微调的 GPT 模型，可以解决非常困难的编程问题，在数学问题上有显著的性能提升。
  2022 年 1 月，一种用于训练文本和代码嵌入的对比方法，在一系列相关任务（例如线性探测分类、文本搜索和代码搜索）上有所提升。
- 与人类对齐
  三阶段的 ==基于人类反馈的强化学习（RLHF）算法==
### 语言模型的重要里程碑
- ChatGPT
  以类似 InstructGPT 的方式进行训练的，专门针对对话能力进行了优化。
- GPT-4
  将文本输入扩展到多模态信号。
# 3. 大语言模型资源
## 3.1 公开可用的模型检查点或 API
- 百亿参数量级别的模型
	- Flan-T5(110亿)：研究指令微调
	- CodeGen(11B)：探索代码生成能力
	- mT0(13B)：多语言任务
	- PanGu-$\alpha$：中文下游任务
	- LLaMA(65B)：指令遵循
- 千亿参数量级别的模型
	- OPT(175B)：专注于复现和开源，旨在使研究人员能够进行大规模可重复研究
	- BLOOM(176B), BLOOMZ(176B)：适合跨语言泛化研究，在多语言语言建模任务中具有较好的能力
	- OPT-IML：适合研究指令微调效果
- 大语言模型的公共 API
	- GPT-3: ada, babbage (GPT-3 1B), curie (GPT-3 6.7B), davinci (GPT-3 175B; GPT-3 系列中最强大的版本), text-ada-001, text-babbage-001, text-curie-001
	- Codex: code-cushman-001 (Codex 12B 强大多语言版本), code-davinci-002
	- GPT-3.5: code-davinci-002, text-davinci-002, text-davinci-003, gpt-3.5-turbo-0301(ChatGPT)
	- GPT-4: gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314
## 3.2 常用语料库
- Books: BookCorpus, Gutenberg
- CommonCrawl: 最大的开源网络爬虫数据库之一
- Reddit Links: Reddit 是一个社交媒体平台。WebText, OpenWebText, Pushshift
- Wikipedia
- Code: 包括开源许可证的公共代码库 (Github) 和与代码相关的问答平台 (StackOverflows)，Google BigQuery 数据集
- Others: The Piles, ROOTS
通常需要混合使用不同的数据源。
代表性 LLM 的预训练语料库：
- GPT-3(175B): 混合数据集 (共 3000 亿 token)，包括 CommomCrawl, WebText2, Books1, Books2, Wikipedia
- PaLM(540B): 由社交媒体对话、过滤后的网页、书籍、Github、多语言维基百科和新闻组成的预训练数据集，共包含 7800 亿 token
- LLaMA: CommonCrawl, C4, Github, Wikipedia, 书籍, ArXiv, StackExchange
## 3.3 代码库资源
- Transformers
- DeepSpeed
- Megatron-LM
- JAX
- Colossal-AI
- BMTrain
- FastMoE
# 4. 预训练
## 4.1 数据收集
### 4.1.1 数据来源
- 通用文本数据
	- 网页：多样化、泛化能力
	  过滤和处理以提高数据质量非常重要
	- 对话文本：对话能力、问答任务
	  多个参与者的处理：将对话转换成树形结构，其中每句话与回应它的话语相连。
	  过度引入对话数据的风险：陈述性指令和直接疑问句被错误地认为是对话的开始
	- 书籍：更正式的长文本，学习语言知识、建模长期依赖关系、生成叙述性和连贯的文本
	  通常采用Books3 和 Bookcorpus2 数据集，可在 Pile 数据集中获得
- 专用文本数据
	- 多语言文本：多语言的理解和生成能力
	- 科学文本：科学和推理任务
	  标记化和预处理将不同格式的数据转化为可以被语言模型处理的统一形式
	- 代码：提高编写程序的质量、复杂推理能力
	  ==将推理任务格式化为代码的形式可以帮助 LLM 生成更准确的结果==
### 4.1.2 数据预处理
- 质量过滤
	- 基于分类器的方法
	  可能导致有偏的预训练语料库、减少语料库的多样性
	- 基于启发式的方法
		- 基于语言的过滤
		- 基于度量的过滤：困惑度 (perplexity)
		- 基于统计的过滤
		- 基于关键词的过滤
- 去重：重复数据会降低语言模型的多样性，可能导致训练过程不稳定，从而影响模型性能
  可以在句子级、文档级和数据集级等不同粒度上去重
	- 句子级：删除包含重复单词和短语的低质量句子，它们可能会在语言建模中引入==重复模式==
	- 文档级：现有研究主要依靠文档之间的==表层特征（例如单词和 n 元的重叠）的重叠比率==来检测和删除包含相似内容的重复文档
	- 数据集级：从训练集中删除测试机可能出现的重复文本，防止训练集和评估集之间的重叠
- 隐私去除：删除*可识别个人信息 (PII)*
	- 采用基于规则的方法，例如关键字识别
	- 去重可以在一定程度上降低隐私风险
- 分词：将原始文本分割成词序列
	- ==SentencePiece== 为预训练语料库训练定制化的分词器
	- 字节级的 ==Byte Pair Encoding (BPE) 算法==确保分词后的信息不会丢失
### 4.1.3 预训练数据对大语言模型的影响
- 混合来源
	- 通过在来自不同来源的文本数据上进行预训练，LLM 可以获得广泛的知识，并可能会展现出强大的泛化能力
	- 需要仔细设置预训练数据的分布，这可能会影响 LLM 在下游任务上的性能
- 预训练数据的数量
	- 在给定的计算预算下，采用相等规模的模型参数和训练 token 是必要的
	- 使用更多的数据和更长时间的训练，较小的模型也可以实现良好的性能，应该更加关注高质量数据的数量
- 预训练数据的质量
	- 在清理后的数据上预训练 LLM 可以提高性能
	- 重复数据可能会导致
		- “双下降现象”（性能最初恶化，随后得到改善）
		- 训练过程不稳定
		- 降低 LLM 从上下文中复制的能力，进一步影响 LLM 在 ICL 中的泛化能力
## 4.2 架构
### 4.2.1 主流架构
- 编码器-解码器架构
- 因果解码器架构
  采用单向注意力掩码，以确保每个输入 token 只能关注过去的 token 和它本身。
  GPT 系列模型是基于因果解码器架构开发的。模型规模的扩大在增加这种模型架构的能力方面起到了重要作用。
- ==前缀解码器架构==（非因果解码器架构）
  修正了因果解码器的掩码机制，以使其能够对前缀 token 执行双向注意力，并仅对生成的 token 执行单向注意力。
  可以训练因果解码器，然后将其转换为前缀解码器以加速收敛。
==混合专家 (MoE)==：通过增加专家的数量或总参数大小，性能会有显著的改进。
![[三种主流架构的注意力模式比较.png]]
### 4.2.2 详细配置
- 标准化：缓解训练不稳定的问题。
  层标准化 (Layer Norm, LN) 的位置对LLM 的性能至关重要。最初的 Transformer 使用后置 LN，大多数 LLM 采用前置 LN 以实现更稳定的训练，尽管会带来一定的性能损失。
  基于前置LN，Sandwich-LN 在残差连接之前添加额外的 LN，以避免数值爆炸，而 Sandwich-LN 有时无法稳定 LLM 的训练，可能导致训练崩溃。
  LN的替代方案：==RMS Norm 在训练速度和性能方面优越、DeepNorm 表现出更好的训练稳定性。==
  ==在嵌入层后添加额外的 LN 可以稳定 LLM 的训练，但往往会导致显著的性能下降。==
- 激活函数
- 位置编码
- 注意力机制和偏置
### 4.2.3 预训练任务
- 语言建模 (LM)
  预训练仅包含解码器的 LLM 的最常用的目标。
  给定一个token 序列 $x = {x_1, x_2, \dots, x_n}$，LM 任务旨在基于序列中前面的 token $x_{<i}$，自回归地预测目标 token $x_i$，通常地训练目标是最大化似然函数 $L_{LM}(x) = \displaystyle\sum_{i=1}^{n} \log P(x_i|x_{<i})$.
  变体：前缀语言建模任务，预训练具有前缀解码器架构的模型
- 去噪自编码任务 (DAE)
  输入有随机替换区间的损坏样本，通过自回归地恢复替换区间来进行训练。
### 4.2.4 总结与讨论
- 通过使用语言模型目标进行预训练，因果解码器架构似乎可以实现更优越地零样本和小样本泛化能力。
- 因果解码器中已经广泛观察到了扩展法则。
- ==对于编码器-解码器模型的更详细的研究仍然缺乏，当前仍需要更多架构和预训练任务的研究，以分析架构和预训练任务的选择如何影响 LLM 的能力，特别是对于编码器-解码器架构。==
## 4.3 模型训练
### 4.3.1 优化设置
- 批量训练
- 学习率
- 优化器
- 稳定训练
### 4.3.2 可扩展的训练技术
- 3D 并行
	- 数据并行
	- 流水线并行
	- 张量并行
- ZeRO
- 混合精度训练
- 整体训练建议
# 5. 大语言模型的适配微调
指令微调 (instruction tuning) 旨在增强（或解锁）LLM 的能力，对齐微调 (alignment tuning) 旨在将 LLM 的行为与人类的价值观或偏好对齐。
## 5.1 指令微调
![[Pasted image 20240310212629.png]]
### 5.1.1 格式化实例的构建
通常情况下，一个指令格式的实例包括一个任务描述（称为**指令**），一对输入-输出以及少量示例。
![[Pasted image 20240310215057.png]]
#### 两种主要的构建格式化示例的方法
- 格式化已有数据集
- 格式化人类需求
#### 构建实例的关键因素
- 增加指令
  扩大任务数量可以极大地提高 LLM 的泛化能力。从例如长度、结构和创造力等多个方面增强任务描述的多样性也是有益的。少量实例通常可以使模型的泛化性能达到饱和，然而，将某些任务的实例数量进一步增加（例如数百个）可能会潜在地导致过拟合并影响模型性能。
- 设计格式
总的来说
- 指令的多样性似乎比实例数量更重要
- 邀请标注者构建人类真实需求的任务比使用特定数据集的任务更有用，==但目前仍缺乏如何标注来满足人类需求指令的指南，使得任务构建在某种程度上更具启发性==。
### 5.1.2 指令微调策略
- 平衡数据分布
- 结合指令微调和预训练
## 5.2 对齐微调
## 5.3 高效微调
# 6. 使用
## 6.1 上下文学习
## 6.2 思维链提示
# 7 能力评测
## 7.1 基础评测任务
![[Pasted image 20240307222732.png]]
### 7.1.1 语言生成
- 语言建模：语言建模是LLM 的基本能力，旨在基于前一个token 预测下一个token，主要关注基本的语言理解和生成能力。
### 7.1.2 知识利用
### 7.1.3 复杂推理
## 7.2 高级能力评估
### 7.2.1 与人类对齐
### 7.2.2 与外部环境的互动
### 7.2.3 工具使用
## 7.3 公开基准和经验性分析
# 8. 总结与未来方向
- 理论与原理
- 模型架构
- 模型训练
- 模型应用
- 安全与对齐
- 应用与生态